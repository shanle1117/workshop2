# ---- LLM / Ollama settings (used by src/settings_llm.py) ----
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# Enable or disable the LLM integration (1 = on, 0 = off)
LLM_ENABLED=1

# Request timeout in seconds (optional, default is 60 if not set)
LLM_REQUEST_TIMEOUT=60

# ---- Django (optional, useful for later deployment) ----
DJANGO_DEBUG=True
DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1